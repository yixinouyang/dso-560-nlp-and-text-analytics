{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from fuzzywuzzy import process\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv('full_data.csv')\n",
    "outfit_comb_df = pd.read_csv('outfit_combinations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean full_df\n",
    "df = full_df.drop(['mpn','created_at','updated_at','deleted_at','bc_product_id','labels','brand_canonical_url'], axis=1).groupby('product_id').first().reset_index().fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    '''\n",
    "    remove stopword and do lemmatization, remove punctuations\n",
    "    convert multiple whitespace into one, lowercase\n",
    "    \n",
    "    Parameter:\n",
    "    text: str\n",
    "    '''\n",
    "    text = ' '.join([token.lemma_ for token in nlp(text) if not token.is_stop])\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).lower()\n",
    "    return text\n",
    "\n",
    "def process_details(text):\n",
    "    '''\n",
    "    clean text in 'details' field, lowercase, remove '\\n', remove punctuations and digits\n",
    "    convert multiple whitespace into one, remove stopword and do lemmatization\n",
    "    \n",
    "    Parameter:\n",
    "    text: str\n",
    "    '''\n",
    "    text = re.sub(r'\\n', ' ', text).lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = ' '.join([token.lemma_ for token in nlp(text) if not token.is_stop])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean description and details columns\n",
    "df.description = df.description.apply(process_text)\n",
    "df.details = df.details.apply(process_details)\n",
    "\n",
    "# combine description and details columns for further embeddings\n",
    "df['text'] = df['description']+df['details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outfit_type(text):\n",
    "    '''\n",
    "    clean text in 'outfit_item_type' field, lowercase, remove punctuations and digits and whitespace\n",
    "    \n",
    "    Parameter:\n",
    "    text: str\n",
    "    '''\n",
    "    text = re.sub(r'[^a-z]', '', text.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean outfit_item_type column\n",
    "outfit_comb_df.outfit_item_type = outfit_comb_df.outfit_item_type.apply(process_outfit_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_on_id(product_id):\n",
    "    '''\n",
    "    look up an outfit_id by a product_id in outfit_comb_df, and print all items under that outfit_id\n",
    "    select first outfit_id if there are multiple outfit_id\n",
    "    \n",
    "    Parameter:\n",
    "    product_id: str\n",
    "        product unique id. make sure it's uppercase and appears in outfit_comb_df\n",
    "    '''\n",
    "    print('\\nOutput')\n",
    "    outfit_id = outfit_comb_df[outfit_comb_df.product_id==product_id].iloc[0].outfit_id\n",
    "    for index, row in outfit_comb_df[outfit_comb_df.outfit_id==outfit_id].iterrows():\n",
    "        print(f'{row.outfit_item_type}: {row.product_full_name} ({row.product_id})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_on_doc2vec(outfit_type, brand_category, brand, text):\n",
    "    '''\n",
    "    find most similar product given outfit_type, brand_category, brand, text\n",
    "    sentence embedding by doc2vec\n",
    "    recommend outfit combination \n",
    "    \n",
    "    Parameters:\n",
    "    outfit_type: str\n",
    "        outfit type, shoe/bottom/top/accessory/onepiece (can be empty)\n",
    "    brand_category: str\n",
    "        band category, must appear in df (can be empty)\n",
    "    brand: str\n",
    "        band name, must appear in df (can be empty)\n",
    "    text: str\n",
    "        descrption+details (can be empty)\n",
    "    '''\n",
    "    full_product_id_list = list(df.product_id.unique())\n",
    "    sme_product_id_list = list(outfit_comb_df[outfit_comb_df.outfit_item_type==outfit_type].product_id.unique())\n",
    "    \n",
    "    # filter df by brand_category and brand\n",
    "    train_df = df.copy()\n",
    "    if brand_category:\n",
    "        train_df = train_df[train_df.brand_category==brand_category]\n",
    "    if brand:\n",
    "        train_df = train_df[train_df.brand==brand]\n",
    "    \n",
    "    # doc2vec embedding\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_df.text)]\n",
    "    model = Doc2Vec(documents, vector_size=50, window=4, min_count=2, workers=4)\n",
    "    \n",
    "    # find most similar index given new text\n",
    "    vector = model.infer_vector(text.split())\n",
    "    index = model.docvecs.most_similar([vector])[0][0]\n",
    "    \n",
    "    # check if the result is in outfit_comb_df\n",
    "    if train_df.iloc[index,].product_id in sme_product_id_list:\n",
    "        recommend_on_id(train_df.iloc[index,].product_id)\n",
    "    else:\n",
    "        # if not, filter df by outfit item type and re-train the doc2vec model\n",
    "        train_df = train_df[train_df.product_id.isin(sme_product_id_list)]\n",
    "        documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_df.text)]\n",
    "        model = Doc2Vec(documents, vector_size=50, window=4, min_count=2, workers=4)\n",
    "        \n",
    "        # find most similar index given new text\n",
    "        index = model.docvecs.most_similar([vector])[0][0]\n",
    "        recommend_on_id(train_df.iloc[index,].product_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_brand_category(text):\n",
    "    '''\n",
    "    make sure input is either empty string or a brand category in df\n",
    "    if not, give candidate list by fuzzy match and ask to re-enter\n",
    "    \n",
    "    Parameters:\n",
    "    text: str\n",
    "        brand category (can be empty)\n",
    "    '''\n",
    "    if text:\n",
    "        brand_category_list = list(df.brand_category.unique())\n",
    "        candidate = process.extractBests(text,brand_category_list)\n",
    "        while candidate[0][1] != 100:\n",
    "            print('Do you mean?')\n",
    "            for i in candidate:\n",
    "                print(i[0], 'similarity:',i[1])\n",
    "            text = input('brand category (left blank if none): ')\n",
    "            if text:\n",
    "                candidate = process.extractBests(text,brand_category_list)\n",
    "            else:\n",
    "                return text\n",
    "        return candidate[0][0] \n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_brand(text):\n",
    "    '''\n",
    "    make sure input is either empty string or a brand name in df\n",
    "    if not, give candidate list by fuzzy match and ask to re-enter\n",
    "    \n",
    "    Parameters:\n",
    "    text: str\n",
    "        brand category (can be empty)\n",
    "    '''\n",
    "    if text:\n",
    "        brand_list = list(df.brand.unique())\n",
    "        candidate = process.extractBests(text,brand_list)\n",
    "        while candidate[0][1] != 100:\n",
    "            print('Do you mean?')\n",
    "            for i in candidate:\n",
    "                print(i[0], 'similarity:',i[1])\n",
    "            text = input('brand (left blank if none): ')\n",
    "            if text:\n",
    "                candidate = process.extractBests(text,brand_list)\n",
    "            else:\n",
    "                return text\n",
    "        return candidate[0][0] \n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input\n",
      "outfit type [shoe/bottom/top/accessory/onepiece]: shoe\n",
      "product id (left blank if none): 01DMBRYVA2ZFDYRYY5TRQZJTBD)\n",
      "Do you mean?\n",
      "01DMBRYVA2ZFDYRYY5TRQZJTBD similarity: 100\n",
      "01DMBRYVA2PEPWFTT7RMP5AA1T similarity: 54\n",
      "01DMBRYVA2Q2ST7MNYR6EEY4TK similarity: 54\n",
      "01DMBRYVA2P5H24WK0HTK4R0A1 similarity: 50\n",
      "01DPBV967NDZSFTDMYPDRTMZYB similarity: 50\n"
     ]
    }
   ],
   "source": [
    "print('Input')\n",
    "\n",
    "# ask user to enter outfit item type\n",
    "outfit_type = process_outfit_type(input('outfit type [shoe/bottom/top/accessory/onepiece]: '))\n",
    "\n",
    "# make sure outfit item type is entered correctly\n",
    "while outfit_type not in ['shoe','bottom','top','accessory','onepiece']:\n",
    "    print('Wrong input')\n",
    "    outfit_type = process_outfit_type(input('outfit type [shoe/bottom/top/accessory/onepiece]: '))\n",
    "\n",
    "# ask user to enter product_id\n",
    "product_id = input('product id (left blank if none): ').upper()\n",
    "\n",
    "if product_id:\n",
    "    if product_id in list(outfit_comb_df['product_id']):\n",
    "        recommend_on_id(product_id)\n",
    "        \n",
    "    elif product_id in list(df['product_id']):\n",
    "        text = str(df[df.product_id==product_id].text)\n",
    "        recommend_on_doc2vec(outfit_type,'','',text)\n",
    "        \n",
    "    else:\n",
    "        print('Do you mean?')\n",
    "        for i in process.extractBests(product_id,df['product_id']):\n",
    "            print(i[0], 'similarity:', i[1])\n",
    "\n",
    "else:\n",
    "    brand_category = check_brand_category(input('brand category (left blank if none): '))\n",
    "    band = check_brand(input('brand (left blank if none): '))\n",
    "    description = input('description (left blank if none): ')\n",
    "    details = input('details (left blank if none): ')\n",
    "    text = process_text(description+details)\n",
    "    recommend_on_doc2vec(outfit_type, brand_category, band, text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
