{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Import-Dependencies-and-Load-in-Dataset\" data-toc-modified-id=\"Import-Dependencies-and-Load-in-Dataset-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Import Dependencies and Load in Dataset</a></span></li><li><span><a href=\"#Pandas-Exploratory-Data-Analysis\" data-toc-modified-id=\"Pandas-Exploratory-Data-Analysis-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Pandas Exploratory Data Analysis</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Show-the-First/Last-Rows-of-Dataset\" data-toc-modified-id=\"Show-the-First/Last-Rows-of-Dataset-2.0.1\"><span class=\"toc-item-num\">2.0.1&nbsp;&nbsp;</span>Show the First/Last Rows of Dataset</a></span></li><li><span><a href=\"#Drop-Unnecessary-Pandas-Column\" data-toc-modified-id=\"Drop-Unnecessary-Pandas-Column-2.0.2\"><span class=\"toc-item-num\">2.0.2&nbsp;&nbsp;</span>Drop Unnecessary Pandas Column</a></span></li><li><span><a href=\"#Compute-a-New-Pandas-Series-and-Attach-to-Dataframe-as-Column\" data-toc-modified-id=\"Compute-a-New-Pandas-Series-and-Attach-to-Dataframe-as-Column-2.0.3\"><span class=\"toc-item-num\">2.0.3&nbsp;&nbsp;</span>Compute a New Pandas Series and Attach to Dataframe as Column</a></span></li><li><span><a href=\"#Count-Number-of-Rows-in-Dataframe-Meet-Some-Criteria\" data-toc-modified-id=\"Count-Number-of-Rows-in-Dataframe-Meet-Some-Criteria-2.0.4\"><span class=\"toc-item-num\">2.0.4&nbsp;&nbsp;</span>Count Number of Rows in Dataframe Meet Some Criteria</a></span></li><li><span><a href=\"#Filter-DataFrame-for-a-Subset-of-Rows\" data-toc-modified-id=\"Filter-DataFrame-for-a-Subset-of-Rows-2.0.5\"><span class=\"toc-item-num\">2.0.5&nbsp;&nbsp;</span>Filter DataFrame for a Subset of Rows</a></span></li></ul></li><li><span><a href=\"#Difference-Between-extractall-and-findall\" data-toc-modified-id=\"Difference-Between-extractall-and-findall-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Difference Between <code>extractall</code> and <code>findall</code></a></span></li></ul></li><li><span><a href=\"#Regex-Character-Classes\" data-toc-modified-id=\"Regex-Character-Classes-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Regex Character Classes</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Find-all-Tweets-That-Start-with-a-Number\" data-toc-modified-id=\"Find-all-Tweets-That-Start-with-a-Number-3.0.1\"><span class=\"toc-item-num\">3.0.1&nbsp;&nbsp;</span>Find all Tweets That Start with a Number</a></span></li><li><span><a href=\"#Find-all-@-Mentions\" data-toc-modified-id=\"Find-all-@-Mentions-3.0.2\"><span class=\"toc-item-num\">3.0.2&nbsp;&nbsp;</span>Find all @ Mentions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Alternative-Method-to-Work-With-Lists-in-Pandas\" data-toc-modified-id=\"Alternative-Method-to-Work-With-Lists-in-Pandas-3.0.2.1\"><span class=\"toc-item-num\">3.0.2.1&nbsp;&nbsp;</span>Alternative Method to Work With Lists in Pandas</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Quantifiers\" data-toc-modified-id=\"Quantifiers-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Quantifiers</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Match-All-Phone-Numbers-(Link)\" data-toc-modified-id=\"Match-All-Phone-Numbers-(Link)-4.0.1\"><span class=\"toc-item-num\">4.0.1&nbsp;&nbsp;</span>Match All Phone Numbers (<a href=\"https://regexr.com/50v17\" target=\"_blank\">Link</a>)</a></span></li><li><span><a href=\"#Parse-Out-Zip-Codes-(Link)\" data-toc-modified-id=\"Parse-Out-Zip-Codes-(Link)-4.0.2\"><span class=\"toc-item-num\">4.0.2&nbsp;&nbsp;</span>Parse Out Zip Codes (<a href=\"https://regexr.com/50v1g\" target=\"_blank\">Link</a>)</a></span></li></ul></li></ul></li><li><span><a href=\"#Capture-Groups\" data-toc-modified-id=\"Capture-Groups-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Capture Groups</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Example:-Parsing-out-Weekday-from-Timestamp-String-(Link)\" data-toc-modified-id=\"Example:-Parsing-out-Weekday-from-Timestamp-String-(Link)-5.0.1\"><span class=\"toc-item-num\">5.0.1&nbsp;&nbsp;</span>Example: Parsing out Weekday from Timestamp String (<a href=\"https://regexr.com/50v0l\" target=\"_blank\">Link</a>)</a></span></li><li><span><a href=\"#Example:-Parsing-Out-Domain-Names\" data-toc-modified-id=\"Example:-Parsing-Out-Domain-Names-5.0.2\"><span class=\"toc-item-num\">5.0.2&nbsp;&nbsp;</span>Example: Parsing Out Domain Names</a></span></li></ul></li><li><span><a href=\"#Non-Capture-Groups\" data-toc-modified-id=\"Non-Capture-Groups-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Non-Capture Groups</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-1-(Link)\" data-toc-modified-id=\"Example-1-(Link)-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;</span>Example 1 <a href=\"https://regexr.com/50t7c\" target=\"_blank\">(Link)</a></a></span></li><li><span><a href=\"#Example-2-(Link)\" data-toc-modified-id=\"Example-2-(Link)-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;</span>Example 2 <a href=\"https://regexr.com/50t7c\" target=\"_blank\">(Link)</a></a></span></li><li><span><a href=\"#Example-3-(Link)\" data-toc-modified-id=\"Example-3-(Link)-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;</span>Example 3 (<a href=\"https://regexr.com/50ush\" target=\"_blank\">Link</a>)</a></span></li></ul></li></ul></li><li><span><a href=\"#Named-Capture-Groups\" data-toc-modified-id=\"Named-Capture-Groups-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Named Capture Groups</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Using-Named-Capture-Groups-in-Pandas-for-Feature-Engineering\" data-toc-modified-id=\"Using-Named-Capture-Groups-in-Pandas-for-Feature-Engineering-6.0.1\"><span class=\"toc-item-num\">6.0.1&nbsp;&nbsp;</span>Using Named Capture Groups in Pandas for Feature Engineering</a></span></li></ul></li></ul></li><li><span><a href=\"#Finding-Repeat-Words-in-Reviews-Using-Backreferences\" data-toc-modified-id=\"Finding-Repeat-Words-in-Reviews-Using-Backreferences-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Finding Repeat Words in Reviews Using Backreferences</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Using-Named-Backreferences\" data-toc-modified-id=\"Using-Named-Backreferences-7.0.1\"><span class=\"toc-item-num\">7.0.1&nbsp;&nbsp;</span>Using Named Backreferences</a></span></li><li><span><a href=\"#Using-Negative-Lookaheads\" data-toc-modified-id=\"Using-Negative-Lookaheads-7.0.2\"><span class=\"toc-item-num\">7.0.2&nbsp;&nbsp;</span>Using Negative Lookaheads</a></span></li><li><span><a href=\"#Negative-Lookbehind\" data-toc-modified-id=\"Negative-Lookbehind-7.0.3\"><span class=\"toc-item-num\">7.0.3&nbsp;&nbsp;</span>Negative Lookbehind</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-all-tweets-that-do-not-begin-with-a-hashtag-or-a-mention.\" data-toc-modified-id=\"Find-all-tweets-that-do-not-begin-with-a-hashtag-or-a-mention.-7.0.3.1\"><span class=\"toc-item-num\">7.0.3.1&nbsp;&nbsp;</span>Find all tweets that do not begin with a hashtag or a mention.</a></span></li></ul></li></ul></li></ul></li><li><span><a href=\"#Exercises\" data-toc-modified-id=\"Exercises-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Exercises</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Use-named-capture-groups-to-find-the-subject-headings-for-these-emails.\" data-toc-modified-id=\"Use-named-capture-groups-to-find-the-subject-headings-for-these-emails.-8.0.0.1\"><span class=\"toc-item-num\">8.0.0.1&nbsp;&nbsp;</span>Use named capture groups to find the subject headings for these emails.</a></span></li><li><span><a href=\"#Find-all-hashtags-or-references-mentioned-in-the-tweets_df-dataset.-Store-them-as-two-separate-columns,-one-for-whether-it-is-either-a-@-or-#,-and-the-other-for-the-actual-content-(ie.-the-hello-part-of-#hello).\" data-toc-modified-id=\"Find-all-hashtags-or-references-mentioned-in-the-tweets_df-dataset.-Store-them-as-two-separate-columns,-one-for-whether-it-is-either-a-@-or-#,-and-the-other-for-the-actual-content-(ie.-the-hello-part-of-#hello).-8.0.0.2\"><span class=\"toc-item-num\">8.0.0.2&nbsp;&nbsp;</span>Find all hashtags or references mentioned in the <code>tweets_df</code> dataset. Store them as two separate columns, one for whether it is either a <code>@</code> or <code>#</code>, and the other for the actual content (ie. the <code>hello</code> part of <code>#hello</code>).</a></span></li><li><span><a href=\"#Use-named-capture-groups-to-provide-a-list-of-email-addresses-for-your-security-administrator-to-blacklist-from-your-company's-email-servers.-The-output-should-be-a-list-of-dictionaries:\" data-toc-modified-id=\"Use-named-capture-groups-to-provide-a-list-of-email-addresses-for-your-security-administrator-to-blacklist-from-your-company's-email-servers.-The-output-should-be-a-list-of-dictionaries:-8.0.0.3\"><span class=\"toc-item-num\">8.0.0.3&nbsp;&nbsp;</span>Use named capture groups to provide a <strong>list of email addresses</strong> for your security administrator to blacklist from your company's email servers. The output should be a list of dictionaries:</a></span></li><li><span><a href=\"#Use-a-negative-lookahead-to-capture-all-emails-except-for-the-ones-from-yahoo.com.\" data-toc-modified-id=\"Use-a-negative-lookahead-to-capture-all-emails-except-for-the-ones-from-yahoo.com.-8.0.0.4\"><span class=\"toc-item-num\">8.0.0.4&nbsp;&nbsp;</span>Use a negative lookahead to capture all emails except for the ones from <code>yahoo.com</code>.</a></span></li><li><span><a href=\"#Identify-any-IP-addresses-that-should-be-blacklisted\" data-toc-modified-id=\"Identify-any-IP-addresses-that-should-be-blacklisted-8.0.0.5\"><span class=\"toc-item-num\">8.0.0.5&nbsp;&nbsp;</span>Identify any IP addresses that should be blacklisted</a></span></li><li><span><a href=\"#The-word-&quot;AT&amp;T&quot;-is-not-spelled-correctly-in-the-tweets_df-dataset.-Correct-the-misspelling.\" data-toc-modified-id=\"The-word-&quot;AT&amp;T&quot;-is-not-spelled-correctly-in-the-tweets_df-dataset.-Correct-the-misspelling.-8.0.0.6\"><span class=\"toc-item-num\">8.0.0.6&nbsp;&nbsp;</span>The word \"AT&amp;T\" is not spelled correctly in the <code>tweets_df</code> dataset. Correct the misspelling.</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Dependencies and Load in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweets_df: pd.DataFrame = pd.read_csv(\"tweets_pandas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Show the First/Last Rows of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   likes  index                          date    topic    handle  \\\n",
       "0      4      3  Mon May 11 03:17:40 UTC 2009  kindle2    tpryan   \n",
       "1      4      4  Mon May 11 03:18:03 UTC 2009  kindle2    vcu451   \n",
       "2      4      5  Mon May 11 03:18:54 UTC 2009  kindle2    chadfu   \n",
       "3      4      6  Mon May 11 03:19:04 UTC 2009  kindle2     SIX15   \n",
       "4      4      7  Mon May 11 03:21:41 UTC 2009  kindle2  yamarama   \n",
       "\n",
       "                                               tweet  \n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...  \n",
       "1  Reading my kindle2...  Love it... Lee childs i...  \n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...  \n",
       "3  @kenburbary You'll love your Kindle2. I've had...  \n",
       "4  @mikefish  Fair enough. But i have the Kindle2...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2</td>\n",
       "      <td>14072</td>\n",
       "      <td>Sun Jun 14 04:31:43 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>proggit</td>\n",
       "      <td>Ask Programming: LaTeX or InDesign?: submitted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>14073</td>\n",
       "      <td>Sun Jun 14 04:32:17 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>sam33r</td>\n",
       "      <td>On that note, I hate Word. I hate Pages. I hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>14074</td>\n",
       "      <td>Sun Jun 14 04:36:34 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>iamtheonlyjosie</td>\n",
       "      <td>Ahhh... back in a *real* text editing environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>14075</td>\n",
       "      <td>Sun Jun 14 21:36:07 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>plutopup7</td>\n",
       "      <td>Trouble in Iran, I see. Hmm. Iran. Iran so far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>14076</td>\n",
       "      <td>Sun Jun 14 21:36:17 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>captain_pete</td>\n",
       "      <td>Reading the tweets coming out of Iran... The w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     likes  index                          date  topic           handle  \\\n",
       "493      2  14072  Sun Jun 14 04:31:43 UTC 2009  latex          proggit   \n",
       "494      0  14073  Sun Jun 14 04:32:17 UTC 2009  latex           sam33r   \n",
       "495      4  14074  Sun Jun 14 04:36:34 UTC 2009  latex  iamtheonlyjosie   \n",
       "496      0  14075  Sun Jun 14 21:36:07 UTC 2009   iran        plutopup7   \n",
       "497      0  14076  Sun Jun 14 21:36:17 UTC 2009   iran     captain_pete   \n",
       "\n",
       "                                                 tweet  \n",
       "493  Ask Programming: LaTeX or InDesign?: submitted...  \n",
       "494  On that note, I hate Word. I hate Pages. I hat...  \n",
       "495  Ahhh... back in a *real* text editing environm...  \n",
       "496  Trouble in Iran, I see. Hmm. Iran. Iran so far...  \n",
       "497  Reading the tweets coming out of Iran... The w...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Drop Unnecessary Pandas Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   likes                          date    topic    handle  \\\n",
       "0      4  Mon May 11 03:17:40 UTC 2009  kindle2    tpryan   \n",
       "1      4  Mon May 11 03:18:03 UTC 2009  kindle2    vcu451   \n",
       "2      4  Mon May 11 03:18:54 UTC 2009  kindle2    chadfu   \n",
       "3      4  Mon May 11 03:19:04 UTC 2009  kindle2     SIX15   \n",
       "4      4  Mon May 11 03:21:41 UTC 2009  kindle2  yamarama   \n",
       "\n",
       "                                               tweet  \n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...  \n",
       "1  Reading my kindle2...  Love it... Lee childs i...  \n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...  \n",
       "3  @kenburbary You'll love your Kindle2. I've had...  \n",
       "4  @mikefish  Fair enough. But i have the Kindle2...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get rid of some columns we don't care about\n",
    "tweets_df.drop(columns=[\"index\"], inplace=True)\n",
    "# preview the dataset\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "### Compute a New Pandas Series and Attach to Dataframe as Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   likes                          date    topic    handle  \\\n",
       "0      4  Mon May 11 03:17:40 UTC 2009  kindle2    tpryan   \n",
       "1      4  Mon May 11 03:18:03 UTC 2009  kindle2    vcu451   \n",
       "2      4  Mon May 11 03:18:54 UTC 2009  kindle2    chadfu   \n",
       "3      4  Mon May 11 03:19:04 UTC 2009  kindle2     SIX15   \n",
       "4      4  Mon May 11 03:21:41 UTC 2009  kindle2  yamarama   \n",
       "\n",
       "                                               tweet  tweet_length  \n",
       "0  @stellargirl I loooooooovvvvvveee my Kindle2. ...           111  \n",
       "1  Reading my kindle2...  Love it... Lee childs i...            58  \n",
       "2  Ok, first assesment of the #kindle2 ...it fuck...            58  \n",
       "3  @kenburbary You'll love your Kindle2. I've had...           140  \n",
       "4  @mikefish  Fair enough. But i have the Kindle2...            75  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get length of tweets in characters\n",
    "tweets_df[\"tweet_length\"] = tweets_df[\"tweet\"].str.len()\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Count Number of Rows in Dataframe Meet Some Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of times Obama appears in tweets\n",
    "tweets_df[\"tweet\"].str.contains(r'\\bObama\\b').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Filter DataFrame for a Subset of Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:29:20 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>mandanicole</td>\n",
       "      <td>how can you not love Obama? he makes jokes abo...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>Mon May 11 03:32:42 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>jpeb</td>\n",
       "      <td>Check this video out -- President Obama at the...</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon May 11 03:32:48 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>kylesellers</td>\n",
       "      <td>@Karoli I firmly believe that Obama/Pelosi hav...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:33:38 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>theviewfans</td>\n",
       "      <td>House Correspondents dinner was last night who...</td>\n",
       "      <td>106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun May 17 17:32:00 UTC 2009</td>\n",
       "      <td>aig</td>\n",
       "      <td>KennyTRoland</td>\n",
       "      <td>?Obama Administration Must Stop Bonuses to AIG...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    likes                          date  topic        handle  \\\n",
       "9       4  Mon May 11 03:29:20 UTC 2009  obama   mandanicole   \n",
       "10      2  Mon May 11 03:32:42 UTC 2009  obama          jpeb   \n",
       "11      0  Mon May 11 03:32:48 UTC 2009  obama   kylesellers   \n",
       "12      4  Mon May 11 03:33:38 UTC 2009  obama   theviewfans   \n",
       "48      0  Sun May 17 17:32:00 UTC 2009    aig  KennyTRoland   \n",
       "\n",
       "                                                tweet  tweet_length  \n",
       "9   how can you not love Obama? he makes jokes abo...            57  \n",
       "10  Check this video out -- President Obama at the...           101  \n",
       "11  @Karoli I firmly believe that Obama/Pelosi hav...           140  \n",
       "12  House Correspondents dinner was last night who...           106  \n",
       "48  ?Obama Administration Must Stop Bonuses to AIG...            85  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter dataframe for only tweets that contain \n",
    "tweets_df[tweets_df[\"tweet\"].str.contains(r'\\bObama\\b')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference Between `extractall` and `findall`\n",
    "\n",
    "The `extractall` method will return a fanned-out multi-dimensional index. For example, in the example below, the primary index is `0`, but there are sub-indices for `stellargirl` (`0`), `loooooooovvvvvveee` (`1`), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>stellargirl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>loooooooovvvvvveee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kindle2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0\n",
       "  match                    \n",
       "0 0             stellargirl\n",
       "  1      loooooooovvvvvveee\n",
       "  2                 Kindle2\n",
       "  3                     Not\n",
       "  4                    that"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"tweet\"].str.extractall(r'\\b(\\w{3,})\\b').head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `findall` method will return a list of results (or an empty list if there is no match)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [stellargirl, loooooooovvvvvveee, Kindle2, Not...\n",
       "1    [Reading, kindle2, Love, Lee, childs, good, read]\n",
       "2     [first, assesment, the, kindle2, fucking, rocks]\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"tweet\"].str.findall(r'\\b(\\w{3,})\\b').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regex Character Classes\n",
    "\n",
    "There are often shortcut keywords you can use instead of typing out every possible character you want to match against. For instance, instead of `[a-zA-Z0-9]`, for all practical purposes, you can type out `/w`.\n",
    "\n",
    "![Character Classes](images/character_chars.png \"Regex character classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "### Find all Tweets That Start with a Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "* [Non-Match Example](https://regexr.com/50ur7)\n",
    "* [Match Example](https://regexr.com/50urj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>2</td>\n",
       "      <td>Mon May 11 03:27:58 UTC 2009</td>\n",
       "      <td>twitter</td>\n",
       "      <td>delpop</td>\n",
       "      <td>45 Pros You Should Be Following on Twitter - h...</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>2</td>\n",
       "      <td>Tue Jun 02 06:53:45 UTC 2009</td>\n",
       "      <td>eating</td>\n",
       "      <td>Fitness_101</td>\n",
       "      <td>10 tips for healthy eating ? ResultsBy Fitness...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jun 14 04:36:07 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>QuadError</td>\n",
       "      <td>7 hours. 7 hours of inkscape crashing, normall...</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     likes                          date    topic       handle  \\\n",
       "242      2  Mon May 11 03:27:58 UTC 2009  twitter       delpop   \n",
       "430      2  Tue Jun 02 06:53:45 UTC 2009   eating  Fitness_101   \n",
       "482      0  Sun Jun 14 04:36:07 UTC 2009    latex    QuadError   \n",
       "\n",
       "                                                 tweet  tweet_length  \n",
       "242  45 Pros You Should Be Following on Twitter - h...            62  \n",
       "430  10 tips for healthy eating ? ResultsBy Fitness...            86  \n",
       "482  7 hours. 7 hours of inkscape crashing, normall...           140  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[tweets_df[\"tweet\"].str.contains(r'^[0-9]')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "### Find all @ Mentions\n",
    "We'll use the `\\w` character class to match for mentions (ie. `@ychennay`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>111</td>\n",
       "      <td>[@stellargirl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>140</td>\n",
       "      <td>[@kenburbary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>75</td>\n",
       "      <td>[@mikefish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:22:00 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>GeorgeVHulme</td>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "      <td>67</td>\n",
       "      <td>[@richardebaker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon May 11 03:32:48 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>kylesellers</td>\n",
       "      <td>@Karoli I firmly believe that Obama/Pelosi hav...</td>\n",
       "      <td>140</td>\n",
       "      <td>[@Karoli]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>Wed Jun 10 15:32:06 UTC 2009</td>\n",
       "      <td>visa card</td>\n",
       "      <td>_abi_</td>\n",
       "      <td>dearest @google, you rich bastards! the VISA c...</td>\n",
       "      <td>107</td>\n",
       "      <td>[@google]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jun 14 04:35:53 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>LoonyLongbottom</td>\n",
       "      <td>@Iheartseverus we love you too and don't want ...</td>\n",
       "      <td>81</td>\n",
       "      <td>[@Iheartseverus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jun 14 21:36:09 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>jamespenycate</td>\n",
       "      <td>Monday already. Iran may implode. Kitchen is a...</td>\n",
       "      <td>140</td>\n",
       "      <td>[@annagoss, @sebulous, @goldpanda]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>4</td>\n",
       "      <td>Sat Jun 13 16:24:15 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>A_TALL_BLONDE</td>\n",
       "      <td>i lam so in love with Bobby Flay... he is my f...</td>\n",
       "      <td>136</td>\n",
       "      <td>[@terrysimpson, @bflay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jun 14 04:31:12 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>rooney_tunes</td>\n",
       "      <td>I just created my first LaTeX file from scratc...</td>\n",
       "      <td>128</td>\n",
       "      <td>[@amandabittner]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     likes                          date       topic           handle  \\\n",
       "0        4  Mon May 11 03:17:40 UTC 2009     kindle2           tpryan   \n",
       "3        4  Mon May 11 03:19:04 UTC 2009     kindle2            SIX15   \n",
       "4        4  Mon May 11 03:21:41 UTC 2009     kindle2         yamarama   \n",
       "5        4  Mon May 11 03:22:00 UTC 2009     kindle2     GeorgeVHulme   \n",
       "11       0  Mon May 11 03:32:48 UTC 2009       obama      kylesellers   \n",
       "..     ...                           ...         ...              ...   \n",
       "474      0  Wed Jun 10 15:32:06 UTC 2009   visa card            _abi_   \n",
       "481      0  Sun Jun 14 04:35:53 UTC 2009       latex  LoonyLongbottom   \n",
       "485      0  Sun Jun 14 21:36:09 UTC 2009        iran    jamespenycate   \n",
       "489      4  Sat Jun 13 16:24:15 UTC 2009  Bobby Flay    A_TALL_BLONDE   \n",
       "490      0  Sun Jun 14 04:31:12 UTC 2009       latex     rooney_tunes   \n",
       "\n",
       "                                                 tweet  tweet_length  \\\n",
       "0    @stellargirl I loooooooovvvvvveee my Kindle2. ...           111   \n",
       "3    @kenburbary You'll love your Kindle2. I've had...           140   \n",
       "4    @mikefish  Fair enough. But i have the Kindle2...            75   \n",
       "5    @richardebaker no. it is too big. I'm quite ha...            67   \n",
       "11   @Karoli I firmly believe that Obama/Pelosi hav...           140   \n",
       "..                                                 ...           ...   \n",
       "474  dearest @google, you rich bastards! the VISA c...           107   \n",
       "481  @Iheartseverus we love you too and don't want ...            81   \n",
       "485  Monday already. Iran may implode. Kitchen is a...           140   \n",
       "489  i lam so in love with Bobby Flay... he is my f...           136   \n",
       "490  I just created my first LaTeX file from scratc...           128   \n",
       "\n",
       "                               mentions  \n",
       "0                        [@stellargirl]  \n",
       "3                         [@kenburbary]  \n",
       "4                           [@mikefish]  \n",
       "5                      [@richardebaker]  \n",
       "11                            [@Karoli]  \n",
       "..                                  ...  \n",
       "474                           [@google]  \n",
       "481                    [@Iheartseverus]  \n",
       "485  [@annagoss, @sebulous, @goldpanda]  \n",
       "489             [@terrysimpson, @bflay]  \n",
       "490                    [@amandabittner]  \n",
       "\n",
       "[88 rows x 7 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"mentions\"] = tweets_df[\"tweet\"].str.findall(r'@\\w+')\n",
    "tweets_df[tweets_df[\"mentions\"].apply(len).gt(0)] # gt is the same as >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown"
   },
   "source": [
    "#### Alternative Method to Work With Lists in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "      <td>111</td>\n",
       "      <td>[@stellargirl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "      <td>140</td>\n",
       "      <td>[@kenburbary]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "      <td>75</td>\n",
       "      <td>[@mikefish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:22:00 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>GeorgeVHulme</td>\n",
       "      <td>@richardebaker no. it is too big. I'm quite ha...</td>\n",
       "      <td>67</td>\n",
       "      <td>[@richardebaker]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>Mon May 11 03:32:48 UTC 2009</td>\n",
       "      <td>obama</td>\n",
       "      <td>kylesellers</td>\n",
       "      <td>@Karoli I firmly believe that Obama/Pelosi hav...</td>\n",
       "      <td>140</td>\n",
       "      <td>[@Karoli]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0</td>\n",
       "      <td>Wed Jun 10 15:32:06 UTC 2009</td>\n",
       "      <td>visa card</td>\n",
       "      <td>_abi_</td>\n",
       "      <td>dearest @google, you rich bastards! the VISA c...</td>\n",
       "      <td>107</td>\n",
       "      <td>[@google]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jun 14 04:35:53 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>LoonyLongbottom</td>\n",
       "      <td>@Iheartseverus we love you too and don't want ...</td>\n",
       "      <td>81</td>\n",
       "      <td>[@Iheartseverus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jun 14 21:36:09 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>jamespenycate</td>\n",
       "      <td>Monday already. Iran may implode. Kitchen is a...</td>\n",
       "      <td>140</td>\n",
       "      <td>[@annagoss, @sebulous, @goldpanda]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>4</td>\n",
       "      <td>Sat Jun 13 16:24:15 UTC 2009</td>\n",
       "      <td>Bobby Flay</td>\n",
       "      <td>A_TALL_BLONDE</td>\n",
       "      <td>i lam so in love with Bobby Flay... he is my f...</td>\n",
       "      <td>136</td>\n",
       "      <td>[@terrysimpson, @bflay]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jun 14 04:31:12 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>rooney_tunes</td>\n",
       "      <td>I just created my first LaTeX file from scratc...</td>\n",
       "      <td>128</td>\n",
       "      <td>[@amandabittner]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     likes                          date       topic           handle  \\\n",
       "0        4  Mon May 11 03:17:40 UTC 2009     kindle2           tpryan   \n",
       "3        4  Mon May 11 03:19:04 UTC 2009     kindle2            SIX15   \n",
       "4        4  Mon May 11 03:21:41 UTC 2009     kindle2         yamarama   \n",
       "5        4  Mon May 11 03:22:00 UTC 2009     kindle2     GeorgeVHulme   \n",
       "11       0  Mon May 11 03:32:48 UTC 2009       obama      kylesellers   \n",
       "..     ...                           ...         ...              ...   \n",
       "474      0  Wed Jun 10 15:32:06 UTC 2009   visa card            _abi_   \n",
       "481      0  Sun Jun 14 04:35:53 UTC 2009       latex  LoonyLongbottom   \n",
       "485      0  Sun Jun 14 21:36:09 UTC 2009        iran    jamespenycate   \n",
       "489      4  Sat Jun 13 16:24:15 UTC 2009  Bobby Flay    A_TALL_BLONDE   \n",
       "490      0  Sun Jun 14 04:31:12 UTC 2009       latex     rooney_tunes   \n",
       "\n",
       "                                                 tweet  tweet_length  \\\n",
       "0    @stellargirl I loooooooovvvvvveee my Kindle2. ...           111   \n",
       "3    @kenburbary You'll love your Kindle2. I've had...           140   \n",
       "4    @mikefish  Fair enough. But i have the Kindle2...            75   \n",
       "5    @richardebaker no. it is too big. I'm quite ha...            67   \n",
       "11   @Karoli I firmly believe that Obama/Pelosi hav...           140   \n",
       "..                                                 ...           ...   \n",
       "474  dearest @google, you rich bastards! the VISA c...           107   \n",
       "481  @Iheartseverus we love you too and don't want ...            81   \n",
       "485  Monday already. Iran may implode. Kitchen is a...           140   \n",
       "489  i lam so in love with Bobby Flay... he is my f...           136   \n",
       "490  I just created my first LaTeX file from scratc...           128   \n",
       "\n",
       "                               mentions  \n",
       "0                        [@stellargirl]  \n",
       "3                         [@kenburbary]  \n",
       "4                           [@mikefish]  \n",
       "5                      [@richardebaker]  \n",
       "11                            [@Karoli]  \n",
       "..                                  ...  \n",
       "474                           [@google]  \n",
       "481                    [@Iheartseverus]  \n",
       "485  [@annagoss, @sebulous, @goldpanda]  \n",
       "489             [@terrysimpson, @bflay]  \n",
       "490                    [@amandabittner]  \n",
       "\n",
       "[88 rows x 7 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the mentions column to boolean. Because an empty list is False, and a non-empty list is True, this filters\n",
    "# out all non-empty lists.\n",
    "tweets_df[tweets_df[\"mentions\"].astype(bool)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantifiers\n",
    "\n",
    "Quantifiers let you specify how many times a character or group should be matched.\n",
    "![Quantifiers](images/quantifiers.png \"Regex character classes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Match All Phone Numbers ([Link](https://regexr.com/50v17))\n",
    "In the unwanted callers dataset (`unwanted_calls.csv`), parse out all phone numbers.\n",
    "\n",
    "We'll only consider for the time being phone numbers that follow the format `123-456-7890`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [866-410-0458]\n",
       "1    [619-840-7262]\n",
       "2    [626-691-9090]\n",
       "Name: caller_id_number, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "unwanted_calls_df: pd.DataFrame = pd.read_csv(\"unwanted_calls.csv\")\n",
    "unwanted_calls_df[\"caller_id_number\"].str.findall(r'\\d{3}-\\d{3}-\\d{4}').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "### Parse Out Zip Codes ([Link](https://regexr.com/50v1g))\n",
    "In the `location_center_point_of_the_zip_code` field, we store both zip codes as well as geolocation data (latitudes and longitudes). We'll only consider zip codes with 5 digits (not the +4 digit delivery route)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [ 33324\\n]\n",
       "1    [ 92078\\n]\n",
       "2    [ 07481\\n]\n",
       "Name: location_center_point_of_the_zip_code, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unwanted_calls_df[\"location_center_point_of_the_zip_code\"].str.findall(r'\\s\\d{5}\\n').head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capture Groups\n",
    "\n",
    "[Oracle documentation on Capture Groups:](https://docs.oracle.com/javase/tutorial/essential/regex/groups.html)\n",
    "> Capturing groups are a way to treat **multiple characters as a single unit**. They are created by placing the characters to be grouped inside a set of parentheses. For example, the regular expression `(dog)` creates a single group containing the letters `d`, `o`, and `g`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "### Example: Parsing out Weekday from Timestamp String ([Link](https://regexr.com/50v0l))\n",
    "\n",
    "In the `date` field of `tweets_df`, we have timestamp strings that look like this: `Mon May 11 03:22:30 UTC 2009`. We want to parse out the weekday from this string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "      <th>tweet_length</th>\n",
       "      <th>mentions</th>\n",
       "      <th>day_of_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2</td>\n",
       "      <td>Tue Jun 02 04:39:49 UTC 2009</td>\n",
       "      <td>safeway</td>\n",
       "      <td>neeeelia</td>\n",
       "      <td>waiting in line at safeway.</td>\n",
       "      <td>27</td>\n",
       "      <td>[]</td>\n",
       "      <td>Tue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0</td>\n",
       "      <td>Sun Jun 07 01:12:38 UTC 2009</td>\n",
       "      <td>jquery</td>\n",
       "      <td>TobyJuanKenobi</td>\n",
       "      <td>argghhhh why won't  my jquery appear in safari...</td>\n",
       "      <td>61</td>\n",
       "      <td>[]</td>\n",
       "      <td>Sun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4</td>\n",
       "      <td>Sat May 16 16:19:04 UTC 2009</td>\n",
       "      <td>google</td>\n",
       "      <td>J_Holl</td>\n",
       "      <td>@phyreman9 Google is always a good place to lo...</td>\n",
       "      <td>114</td>\n",
       "      <td>[@phyreman9, @KimbleT]</td>\n",
       "      <td>Sat</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     likes                          date    topic          handle  \\\n",
       "175      2  Tue Jun 02 04:39:49 UTC 2009  safeway        neeeelia   \n",
       "440      0  Sun Jun 07 01:12:38 UTC 2009   jquery  TobyJuanKenobi   \n",
       "32       4  Sat May 16 16:19:04 UTC 2009   google          J_Holl   \n",
       "\n",
       "                                                 tweet  tweet_length  \\\n",
       "175                        waiting in line at safeway.            27   \n",
       "440  argghhhh why won't  my jquery appear in safari...            61   \n",
       "32   @phyreman9 Google is always a good place to lo...           114   \n",
       "\n",
       "                   mentions day_of_week  \n",
       "175                      []         Tue  \n",
       "440                      []         Sun  \n",
       "32   [@phyreman9, @KimbleT]         Sat  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df[\"day_of_week\"] = tweets_df[\"date\"].str.extract(r'^(\\w{3})\\b')\n",
    "tweets_df.sample(len(tweets_df)).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "### Example: Parsing Out Domain Names\n",
    "We want to capture the domain names of different websites. Here, we need to escape the `.` part of `www.google.com`. In regex, `.` means \"anything\". To actually indicate we want to match for the literal `.` period character, we need to escape it, using `\\.`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "websites = open(\"list_of_websites.txt\").readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "cleaned_websites = list(map(lambda website: re.sub(r'\\n', '', website), websites))\n",
    "regex = r'https?:\\/\\/www\\.(\\w+)\\.\\w+'\n",
    "domain_names = pd.Series(cleaned_websites).str.extract(regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Capture Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes you want to group multiple characters into a single unit to apply regex operations on them, but you don't\n",
    "want to actually capture or return their result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "### Example 1 [(Link)](https://regexr.com/50t7c)\n",
    "Using non-capture groups to match for optional text:\n",
    "\n",
    "You want to capture both `child` and `children` in your text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['child', 'children']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "text = \"The word child is singular, but the word children is plural.\"\n",
    "re.findall(r'\\bchild(?:ren)?\\b', text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "### Example 2 [(Link)](https://regexr.com/50t7c)\n",
    "Find all the mentions in the tweets. Mentions start with `@`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-90ef2b85e964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tweet\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'(@\\w+)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets_df' is not defined"
     ]
    }
   ],
   "source": [
    "tweets_df[\"tweet\"].str.findall(r'(@\\w+)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "### Example 3 ([Link](https://regexr.com/50ush))\n",
    "Here we want to match for the dollar amount, but we don't want to include the currency notation (`$` or `USD`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 're' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0237afb29162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mregex_pattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"(?:\\$|(?:USD))([0-9]+)\\.([0-9][0-9])\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Average fast food wage is $9.08, but inflation has increased USD9.23\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregex_pattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 're' is not defined"
     ]
    }
   ],
   "source": [
    "regex_pattern = \"(?:\\$|(?:USD))([0-9]+)\\.([0-9][0-9])\"\n",
    "text = \"Average fast food wage is $9.08, but inflation has increased USD9.23\"\n",
    "results = re.findall(regex_pattern, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Named Capture Groups\n",
    "\n",
    "Often, we might have a hard time keeping track of all the capture groups in our regex. We can use **named capture groups** instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pm', 'pm', 'pm', 'am', 'am']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "file = open(\"mcdonalds-yelp-negative-reviews.csv\", encoding=\"latin1\")\n",
    "reviews = file.read()\n",
    "\n",
    "regex_pattern = r'1?\\d:[0-5]\\d\\s?(am|pm)'\n",
    "\n",
    "re.findall(regex_pattern, reviews)[:5] # what's wrong with this expression?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9:30pm', '7:30 pm', '1:45 pm', '5:48 am', '6:30am']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regex_pattern = r'1?\\d:[0-5]\\d\\s?(?:am|pm)'\n",
    "re.findall(regex_pattern, reviews)[:5] # this looks much better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hour': '9', 'minute': '30', 'indicator': 'pm'}\n",
      "{'hour': '7', 'minute': '30', 'indicator': 'pm'}\n",
      "{'hour': '1', 'minute': '45', 'indicator': 'pm'}\n",
      "{'hour': '2', 'minute': '00', 'indicator': 'pm'}\n",
      "{'hour': '11', 'minute': '30', 'indicator': 'pm'}\n",
      "{'hour': '1', 'minute': '30', 'indicator': 'pm'}\n",
      "{'hour': '9', 'minute': '30', 'indicator': 'pm'}\n",
      "{'hour': '1', 'minute': '11', 'indicator': 'pm'}\n",
      "{'hour': '9', 'minute': '00', 'indicator': 'pm'}\n",
      "{'hour': '7', 'minute': '10', 'indicator': 'pm'}\n",
      "{'hour': '10', 'minute': '14', 'indicator': 'pm'}\n",
      "{'hour': '7', 'minute': '30', 'indicator': 'pm'}\n",
      "{'hour': '1', 'minute': '45', 'indicator': 'pm'}\n",
      "{'hour': '7', 'minute': '41', 'indicator': 'pm'}\n"
     ]
    }
   ],
   "source": [
    "# now, we want to capture the hour, minute, and time of day indicator\n",
    "regex_pattern = r'(?P<hour>1?\\d):(?P<minute>[0-5]\\d)\\s?(?P<indicator>:am|pm)'\n",
    "file.seek(0) # reset the index position\n",
    "reviews = file.readlines()\n",
    "for review in reviews:\n",
    "    match = re.search(regex_pattern, review) # this looks much better\n",
    "    if match:\n",
    "        print(match.groupdict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Named Capture Groups in Pandas for Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "reviews_df = pd.read_csv(\"mcdonalds-yelp-negative-reviews.csv\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1525 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     hour minute indicator\n",
       "0     NaN    NaN       NaN\n",
       "1       9     30        pm\n",
       "2     NaN    NaN       NaN\n",
       "3     NaN    NaN       NaN\n",
       "4     NaN    NaN       NaN\n",
       "...   ...    ...       ...\n",
       "1520  NaN    NaN       NaN\n",
       "1521  NaN    NaN       NaN\n",
       "1522  NaN    NaN       NaN\n",
       "1523  NaN    NaN       NaN\n",
       "1524  NaN    NaN       NaN\n",
       "\n",
       "[1525 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df[\"review\"].str.extract(r'(?P<hour>1?\\d):(?P<minute>[0-5]\\d)\\s?(?P<indicator>:am|pm)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Repeat Words in Reviews Using Backreferences\n",
    "You can refer to capture groups earlier in your expression using **backreferences**. For instance, `\\1` means the first capture group in your expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regex_pattern = r'(\\b\\w*burgers?\\b).+\\b\\1\\b'\n",
    "file.seek(0)\n",
    "reviews = file.readlines()\n",
    "\n",
    "for review in reviews:\n",
    "    match = re.search(regex_pattern, review)\n",
    "    if match:\n",
    "        print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Named Backreferences\n",
    "\n",
    "If you named a group `BURGER`, you can reference it later with `(?P=BURGER)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "regex_pattern = r'(?P<BURGER>\\b\\w*burgers?\\b).+\\b(?P=BURGER)\\b'\n",
    "file.seek(0)\n",
    "reviews = file.readlines()\n",
    "\n",
    "for review in reviews:\n",
    "    match = re.search(regex_pattern, review)\n",
    "    if match:\n",
    "        print(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Negative Lookaheads\n",
    "\n",
    "Whenever you are thinking *I need to match this expression, but only when the piece of text doesn't say X*, you can use **negative lookaheads**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, to match only the timestamps in McDonalds reviews that happen before **12pm**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('12', '54')\n",
      "('4', '30')\n",
      "('7', '30')\n",
      "('7', '30')\n",
      "('1', '45')\n",
      "('5', '48')\n",
      "('6', '30')\n"
     ]
    }
   ],
   "source": [
    "regex_pattern = r'(1?\\d):([0-5]\\d)\\s?(?!pm)'\n",
    "file.seek(0)\n",
    "reviews = file.readlines()\n",
    "for review in reviews[:100]:\n",
    "    match = re.search(regex_pattern, review)\n",
    "    if match:\n",
    "        print(match.groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we still want to capture the time of day indicator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('5', '00', 'AM')\n",
      "('7', '30', 'so')\n",
      "('5', '48', 'am')\n",
      "('6', '30', 'am')\n"
     ]
    }
   ],
   "source": [
    "regex_pattern = r'(1?\\d):([0-5]\\d)\\s?(?!pm)(\\w{2})'\n",
    "file.seek(0)\n",
    "reviews = file.readlines()\n",
    "for review in reviews[:100]:\n",
    "    match = re.search(regex_pattern, review)\n",
    "    if match:\n",
    "        print(match.groups())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative Lookbehind\n",
    "#### Find all tweets that do not begin with a hashtag or a mention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_pattern = r'^(?<!@)([\\w\\s\\.:]+)'\n",
    "tweets_df[\"extracted\"] = tweets_df[\"tweet\"].str.extract(regex_pattern)\n",
    "tweets_df[[\"tweet\", \"extracted\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises\n",
    "\n",
    "You'll be using the the `tweets_df` Pandas dataframe and `fraudulent_emails.txt` text files for these examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "email_text = open(\"fraudulent_emails.txt\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Use named capture groups to find the subject headings for these emails.\n",
    "**Hint**: Look for the subject line within the email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "# Find the subject headings for these emails.\n",
    "email_text = open(\"fraudulent_emails.txt\").read()\n",
    "re.findall(r'Subject:\\s(.+)', email_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "shown",
    "solution2_first": true
   },
   "source": [
    "#### Find all hashtags or references mentioned in the `tweets_df` dataset. Store them as two separate columns, one for whether it is either a `@` or `#`, and the other for the actual content (ie. the `hello` part of `#hello`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "# Find all hashtags mentioned in the tweets dataset. Store it as a separate column called hashtags.\n",
    "# The \\B is \"not a word boundary\", and it matches because the # (and the @ in the previous example) is not \n",
    "# considered part of a word. Therefore, you need to opposite of a word boundary (a non-word boundary) to match\n",
    "# the case where it begins with a non-word character.\n",
    "\n",
    "# This will correctly NOT match text like she#he, sometext#someothertext\n",
    "tweets_df[\"tweet\"].str.findall(r'\\B(#\\w+)\\b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Use named capture groups to provide a **list of email addresses** for your security administrator to blacklist from your company's email servers. The output should be a list of dictionaries:\n",
    "\n",
    "```python\n",
    "[\n",
    " {\n",
    "     \"username\": \"yuchen\",\n",
    "     \"domain\": \"gmail.com\n",
    " },\n",
    "    # ...\n",
    "]\n",
    "```\n",
    "\n",
    "* Not all emails are malicious! Provide only the list of email addresses from where the email originates from. **Hint**: identify the pattern in the emails that tells you the source of the email.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "regex_pattern = r'Return-Path: \\<(\\w+@\\w+\\.\\w{2,6})\\>'\n",
    "set(re.findall(regex_pattern, email_text)) # this matches only basic emails (myemail@gmail.com)\n",
    "\n",
    "regex_pattern = r'Return-Path: \\<(\\w+@\\w+\\.[\\w+\\.]{1,})\\>'\n",
    "set(re.findall(regex_pattern,email_text)) # this matches more complicated emails with multiple domain names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use a negative lookahead to capture all emails except for the ones from `yahoo.com`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### Identify any IP addresses that should be blacklisted\n",
    "\n",
    "An IPv4 address goes from **1.1.1.1 to 255.255.255.255**. For now, just worry about the number of digits, not whether the value in the address is above `255`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "solution2": "hidden"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "re.findall(r'[1-2]?[0-9]{1,2}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}', email_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "solution2": "hidden",
    "solution2_first": true
   },
   "source": [
    "#### The word \"AT&T\" is not spelled correctly in the `tweets_df` dataset. Correct the misspelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>likes</th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "      <th>topic</th>\n",
       "      <th>handle</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>Mon May 11 03:17:40 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>tpryan</td>\n",
       "      <td>@stellargirl I loooooooovvvvvveee my Kindle2. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon May 11 03:18:03 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>vcu451</td>\n",
       "      <td>Reading my kindle2...  Love it... Lee childs i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon May 11 03:18:54 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>chadfu</td>\n",
       "      <td>Ok, first assesment of the #kindle2 ...it fuck...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>Mon May 11 03:19:04 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>SIX15</td>\n",
       "      <td>@kenburbary You'll love your Kindle2. I've had...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Mon May 11 03:21:41 UTC 2009</td>\n",
       "      <td>kindle2</td>\n",
       "      <td>yamarama</td>\n",
       "      <td>@mikefish  Fair enough. But i have the Kindle2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2</td>\n",
       "      <td>14072</td>\n",
       "      <td>Sun Jun 14 04:31:43 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>proggit</td>\n",
       "      <td>Ask Programming: LaTeX or InDesign?: submitted...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>0</td>\n",
       "      <td>14073</td>\n",
       "      <td>Sun Jun 14 04:32:17 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>sam33r</td>\n",
       "      <td>On that note, I hate Word. I hate Pages. I hat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>4</td>\n",
       "      <td>14074</td>\n",
       "      <td>Sun Jun 14 04:36:34 UTC 2009</td>\n",
       "      <td>latex</td>\n",
       "      <td>iamtheonlyjosie</td>\n",
       "      <td>Ahhh... back in a *real* text editing environm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>14075</td>\n",
       "      <td>Sun Jun 14 21:36:07 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>plutopup7</td>\n",
       "      <td>Trouble in Iran, I see. Hmm. Iran. Iran so far...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>0</td>\n",
       "      <td>14076</td>\n",
       "      <td>Sun Jun 14 21:36:17 UTC 2009</td>\n",
       "      <td>iran</td>\n",
       "      <td>captain_pete</td>\n",
       "      <td>Reading the tweets coming out of Iran... The w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>498 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     likes  index                          date    topic           handle  \\\n",
       "0        4      3  Mon May 11 03:17:40 UTC 2009  kindle2           tpryan   \n",
       "1        4      4  Mon May 11 03:18:03 UTC 2009  kindle2           vcu451   \n",
       "2        4      5  Mon May 11 03:18:54 UTC 2009  kindle2           chadfu   \n",
       "3        4      6  Mon May 11 03:19:04 UTC 2009  kindle2            SIX15   \n",
       "4        4      7  Mon May 11 03:21:41 UTC 2009  kindle2         yamarama   \n",
       "..     ...    ...                           ...      ...              ...   \n",
       "493      2  14072  Sun Jun 14 04:31:43 UTC 2009    latex          proggit   \n",
       "494      0  14073  Sun Jun 14 04:32:17 UTC 2009    latex           sam33r   \n",
       "495      4  14074  Sun Jun 14 04:36:34 UTC 2009    latex  iamtheonlyjosie   \n",
       "496      0  14075  Sun Jun 14 21:36:07 UTC 2009     iran        plutopup7   \n",
       "497      0  14076  Sun Jun 14 21:36:17 UTC 2009     iran     captain_pete   \n",
       "\n",
       "                                                 tweet  \n",
       "0    @stellargirl I loooooooovvvvvveee my Kindle2. ...  \n",
       "1    Reading my kindle2...  Love it... Lee childs i...  \n",
       "2    Ok, first assesment of the #kindle2 ...it fuck...  \n",
       "3    @kenburbary You'll love your Kindle2. I've had...  \n",
       "4    @mikefish  Fair enough. But i have the Kindle2...  \n",
       "..                                                 ...  \n",
       "493  Ask Programming: LaTeX or InDesign?: submitted...  \n",
       "494  On that note, I hate Word. I hate Pages. I hat...  \n",
       "495  Ahhh... back in a *real* text editing environm...  \n",
       "496  Trouble in Iran, I see. Hmm. Iran. Iran so far...  \n",
       "497  Reading the tweets coming out of Iran... The w...  \n",
       "\n",
       "[498 rows x 6 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "solution2": "shown"
   },
   "outputs": [],
   "source": [
    "tweets_df = tweets_df[\"tweet\"].str.replace(r'AT&amp;', 'AT&')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "225px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
