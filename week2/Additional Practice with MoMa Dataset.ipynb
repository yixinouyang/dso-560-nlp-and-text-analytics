{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Artwork-Search\" data-toc-modified-id=\"Artwork-Search-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Artwork Search</a></span><ul class=\"toc-item\"><li><span><a href=\"#Import-Libraries\" data-toc-modified-id=\"Import-Libraries-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Import Libraries</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-in-the-Dataset\" data-toc-modified-id=\"Load-in-the-Dataset-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span>Load in the Dataset</a></span></li><li><span><a href=\"#Examine-the-Dataset\" data-toc-modified-id=\"Examine-the-Dataset-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span>Examine the Dataset</a></span></li></ul></li><li><span><a href=\"#Identify-Positive/Negative-Target-Counts-After-Regex\" data-toc-modified-id=\"Identify-Positive/Negative-Target-Counts-After-Regex-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Identify Positive/Negative Target Counts After Regex</a></span><ul class=\"toc-item\"><li><span><a href=\"#Compute-Scoring-Metrics\" data-toc-modified-id=\"Compute-Scoring-Metrics-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Compute Scoring Metrics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Accuracy\" data-toc-modified-id=\"Accuracy-1.2.1.1\"><span class=\"toc-item-num\">1.2.1.1&nbsp;&nbsp;</span>Accuracy</a></span></li><li><span><a href=\"#Precision\" data-toc-modified-id=\"Precision-1.2.1.2\"><span class=\"toc-item-num\">1.2.1.2&nbsp;&nbsp;</span>Precision</a></span></li><li><span><a href=\"#Recall\" data-toc-modified-id=\"Recall-1.2.1.3\"><span class=\"toc-item-num\">1.2.1.3&nbsp;&nbsp;</span>Recall</a></span></li><li><span><a href=\"#F1-Score\" data-toc-modified-id=\"F1-Score-1.2.1.4\"><span class=\"toc-item-num\">1.2.1.4&nbsp;&nbsp;</span>F1 Score</a></span></li></ul></li><li><span><a href=\"#Remove-Stopwords-and-Perform-Lemmatization\" data-toc-modified-id=\"Remove-Stopwords-and-Perform-Lemmatization-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Remove Stopwords and Perform Lemmatization</a></span><ul class=\"toc-item\"><li><span><a href=\"#Example-of-a-Function-to-Remove-Stopwords-From-Text\" data-toc-modified-id=\"Example-of-a-Function-to-Remove-Stopwords-From-Text-1.2.2.1\"><span class=\"toc-item-num\">1.2.2.1&nbsp;&nbsp;</span>Example of a Function to Remove Stopwords From Text</a></span></li><li><span><a href=\"#Example-of-a-Function-to-Lemmatize-a-Title\" data-toc-modified-id=\"Example-of-a-Function-to-Lemmatize-a-Title-1.2.2.2\"><span class=\"toc-item-num\">1.2.2.2&nbsp;&nbsp;</span>Example of a Function to Lemmatize a Title</a></span></li><li><span><a href=\"#Applying-a-Function-to-an-Entire-Column-in-Pandas\" data-toc-modified-id=\"Applying-a-Function-to-an-Entire-Column-in-Pandas-1.2.2.3\"><span class=\"toc-item-num\">1.2.2.3&nbsp;&nbsp;</span>Applying a Function to an Entire Column in Pandas</a></span></li><li><span><a href=\"#TF-IDF-Vectorize-Your-Documents\" data-toc-modified-id=\"TF-IDF-Vectorize-Your-Documents-1.2.2.4\"><span class=\"toc-item-num\">1.2.2.4&nbsp;&nbsp;</span>TF-IDF Vectorize Your Documents</a></span></li><li><span><a href=\"#Final-Shape-of-Features\" data-toc-modified-id=\"Final-Shape-of-Features-1.2.2.5\"><span class=\"toc-item-num\">1.2.2.5&nbsp;&nbsp;</span>Final Shape of Features</a></span></li></ul></li></ul></li><li><span><a href=\"#Look-at-the-TF-IDF-scores-for-print,-and-define-a-threshold-to-classify-a-document-as-being-is_print-=-True-versus-is_print-=-False.-Use-this-new-threshold,-compute-is_print_tf_idf-(either-True-or-False)\" data-toc-modified-id=\"Look-at-the-TF-IDF-scores-for-print,-and-define-a-threshold-to-classify-a-document-as-being-is_print-=-True-versus-is_print-=-False.-Use-this-new-threshold,-compute-is_print_tf_idf-(either-True-or-False)-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Look at the TF-IDF scores for <code>print</code>, and define a threshold to classify a document as being <code>is_print = True</code> versus <code>is_print = False</code>. Use this new threshold, compute <code>is_print_tf_idf</code> (either True or False)</a></span><ul class=\"toc-item\"><li><span><a href=\"#Compute-Scoring-Metrics\" data-toc-modified-id=\"Compute-Scoring-Metrics-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Compute Scoring Metrics</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artwork Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Background:** You are required to help the MoMA (Museum of Metropolitan Art - original dataset https://www.kaggle.com/momanyc/museum-collection) curation team tag all artworks for specific attributes. Download https://dso-560-nlp-text-analytics.s3.amazonaws.com/moma_artworks.csv. They want to tag all artwork that are from the [print medium](https://www.quora.com/What-is-print-media) so that users can easily search for these keywords and find relevant artwork."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in the Dataset\n",
    "\n",
    "Read the `moma_artworks.csv` file into a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the Dataset\n",
    "\n",
    "Look at the first few rows of the dataset using `df.head()` (substitute `df` for whatever you named your dataframe). Use Pandas' `contains` search to find all artworks that are `prints` in their description or title. Save this as a new column called `is_print`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Positive/Negative Target Counts After Regex\n",
    "1. Provide the number of **positives samples** in this art collection based on your labelling of `is_print`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Provide the number of **negative samples** in this art collection based on your labelling of `is_print`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Identify an example of a false positive using only the regex match you wrote. This will require you to look at all the positive samples and find ones that are not actually related to `is_print`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the example here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Scoring Metrics\n",
    "\n",
    "Use the `Classification` field in the dataset to calculate the following. Consider the `Classification` field to be the \"predicted\", and your `is_print` to be the actual. Compute the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Stopwords and Perform Lemmatization\n",
    "Go back to your original dataframe.\n",
    "\n",
    "1. Remove stopwords (think about what stopwords make sense and which ones make sense given this is an artwork dataset)\n",
    "2. Perform lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "import nltk\n",
    "nltk_stopwords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of a Function to Remove Stopwords From Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(title: str):\n",
    "    tokens = nltk.word_tokenize(title)\n",
    "    filtered_tokens = list(filter(lambda token: token not in nltk_stopwords, tokens))\n",
    "    return \" \".join(filtered_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of a Function to Lemmatize a Title\n",
    "We are using the `map` function in Python to iterate through each token in the title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_title(title: str):\n",
    "    tokens = nltk.word_tokenize(title)\n",
    "    lemmatized_tokens = list(map(lambda token: lemmatizer.lemmatize(token), tokens))\n",
    "    return \" \".join(lemmatized_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying a Function to an Entire Column in Pandas\n",
    "\n",
    "You can apply this function to an entire column (in this case, the `title` column) using Pandas' `apply` function:\n",
    "\n",
    "```python\n",
    "df[\"cleaned_title\"] = df[\"title\"].apply(remove_stopwords)\n",
    "```\n",
    "\n",
    "This will return a new column called `cleaned_title` that has applied the `remove_stopwords` function to each row's `title` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform stopword removal\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform lemmatization\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorize Your Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform count vectorization after stopwords and lemmatization have been applied\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Shape of Features\n",
    "Provide the shape of your new Pandas dataframe (after removing stopwords, lemmatizing, and TF-IDF vectorizing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at the TF-IDF scores for `print`, and define a threshold to classify a document as being `is_print = True` versus `is_print = False`. Use this new threshold, compute `is_print_tf_idf` (either True or False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Scoring Metrics\n",
    "\n",
    "Using your newly computed `is_print_tf_idf` field, compare your search results against the original `is_print` field, calculated using only `contains()`. Explain which one you think would perform better as a search tool, for art visitors looking to search for `print` artworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## answer here\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
