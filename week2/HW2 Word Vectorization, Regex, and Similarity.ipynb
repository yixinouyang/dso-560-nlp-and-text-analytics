{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 (Due 11:59pm PST March 31st, 2020): Word Vectorization, Regex Practice, and Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may work with **one other person on this assignment**. You may also work independently if you prefer.\n",
    "\n",
    "If you just want to be assigned someone to work with, message me on Slack and I will assign you a partner to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Using the **McDonalds Yelp Review CSV file**, **process the reviews**.\n",
    "This means you should think briefly about:\n",
    "* what stopwords to remove (should you add any custom stopwords to the set? Remove any stopwords?)\n",
    "* what regex cleaning you may need to perform (for example, are there different ways of saying `hamburger` that you need to account for?)\n",
    "* stemming/lemmatization (explain in your notebook why you used stemming versus lemmatization). \n",
    "\n",
    "Next, **count-vectorize the dataset**. Use the **`sklearn.feature_extraction.text.CountVectorizer`** examples from `Linear Algebra, Distance and Similarity (Completed).ipynb` and `Text Preprocessing Techniques (Completed).ipynb` (read the last section, `Vectorization Techniques`).\n",
    "\n",
    "I do not want redundant features - for instance, I do not want `hamburgers` and `hamburger` to be two distinct columns in your document-term matrix. Therefore, I'll be taking a look to make sure you've properly performed your cleaning, stopword removal, etc. to reduce the number of dimensions in your dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. **Stopwords, Stemming, Lemmatization Practice**\n",
    "\n",
    "Using the `tale-of-two-cities.txt` file from Week 1:\n",
    "* Count-vectorize the corpus. Treat each sentence as a document.\n",
    "\n",
    "How many features (dimensions) do you get when you:\n",
    "* Perform **stemming and then count-vectorization\n",
    "* Perform **lemmatization** and then **count-vectorization**.\n",
    "* Perform **lemmatization**, remove **stopwords**, and then perform **count-vectorization**?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
